{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading DMS scores from MAVEdb\n",
    "\n",
    "Using the MAVEdb API to get a list of DMS score datasets on human proteins and download the associated CSV files.\n",
    "\n",
    "**MAVEdb**: <https://www.mavedb.org/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get list of DMS score datasets\n",
    "\n",
    "`requests` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import csv\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoresets = requests.get('https://www.mavedb.org/api/scoresets/')\n",
    "assert scoresets.status_code == 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoresets = scoresets.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now keep a dictionary of scoresets with uniprot identifier and scoreset ID. \n",
    "* DMS experiments that targeted the gene promoter (as opposed to the coding sequence) will have field `'uniprot': None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'creation_date': '2019-08-07',\n",
       " 'modification_date': '2019-08-09',\n",
       " 'urn': 'urn:mavedb:00000040-a-4',\n",
       " 'publish_date': '2019-08-07',\n",
       " 'created_by': '0000-0003-1474-605X',\n",
       " 'modified_by': '0000-0003-1474-605X',\n",
       " 'extra_metadata': {},\n",
       " 'abstract_text': 'This study measured the effect of variants in yeast HSP90 under different combinations of temperature (30C or 36C) and presence/absence of salt (0.5 M NaCl). The results explore the adaptive potential of this essential gene.',\n",
       " 'method_text': \"Sequencing reads were filtered based on a minimum Phred quality score of 20 across all 36 bases. For each time point, the log2 ratio of each variant's count to the wild type count was calculated. The score of each variant was calculated as the slope of these log ratios to time in wild type generations. Scores of -0.5 are considered null-like.\",\n",
       " 'short_description': 'Deep mutational scan of all single mutants in a nine-amino acid region of Hsp90 (Hsp82) in Saccharomyces cerevisiae at 36C with 0.5 M NaCl.',\n",
       " 'title': 'Deep mutational scan of HSP90, 36C with salt',\n",
       " 'keywords': [{'text': 'NNN mutagenesis'},\n",
       "  {'text': 'EMPIRIC'},\n",
       "  {'text': 'growth assay'},\n",
       "  {'text': 'regression'}],\n",
       " 'doi_ids': [],\n",
       " 'pubmed_ids': [{'identifier': '24299404',\n",
       "   'url': 'http://www.ncbi.nlm.nih.gov/pubmed/24299404',\n",
       "   'dbversion': None,\n",
       "   'dbname': 'PubMed'}],\n",
       " 'contributors': ['0000-0003-1474-605X'],\n",
       " 'licence': {'long_name': 'CC BY-NC-SA 4.0 (Attribution-NonCommercial-ShareAlike)',\n",
       "  'short_name': 'CC BY-NC-SA 4.0',\n",
       "  'link': 'https://creativecommons.org/licenses/by-nc-sa/4.0/',\n",
       "  'version': '4.0'},\n",
       " 'target': {'name': 'HSP90',\n",
       "  'reference_sequence': {'sequence': 'CAATTTGGTTGGTCTGCTAATATGGAA',\n",
       "   'sequence_type': 'dna'},\n",
       "  'uniprot': {'offset': 581,\n",
       "   'identifier': 'P02829',\n",
       "   'url': 'http://purl.uniprot.org/uniprot/P02829',\n",
       "   'dbversion': None,\n",
       "   'dbname': 'UniProt'},\n",
       "  'ensembl': None,\n",
       "  'refseq': None,\n",
       "  'reference_maps': [{'genome': {'short_name': 'sacCer3/R64',\n",
       "     'organism_name': 'Saccharomyces cerevisiae',\n",
       "     'assembly_identifier': {'identifier': 'GCF_000146045.2',\n",
       "      'url': 'http://www.ncbi.nlm.nih.gov/assembly/GCF_000146045.2',\n",
       "      'dbversion': None,\n",
       "      'dbname': 'GenomeAssembly'}}}],\n",
       "  'scoreset': 'urn:mavedb:00000040-a-4',\n",
       "  'type': 'Protein coding'},\n",
       " 'score_columns': ['hgvs_nt', 'hgvs_splice', 'hgvs_pro', 'score'],\n",
       " 'count_columns': ['hgvs_nt', 'hgvs_splice', 'hgvs_pro'],\n",
       " 'previous_version': None,\n",
       " 'next_version': None,\n",
       " 'current_version': 'urn:mavedb:00000040-a-4',\n",
       " 'variant_count': 189,\n",
       " 'experiment': 'urn:mavedb:00000040-a',\n",
       " 'is_meta_analysis': False,\n",
       " 'data_usage_policy': ''}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoresets[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of scoreset ID and uniprot ID\n",
    "scoresets_dict = dict()\n",
    "for entry in scoresets:\n",
    "    if entry['target']['uniprot'] is not None and \\\n",
    "        entry['target']['reference_maps'][0]['genome']['organism_name'] == 'Homo sapiens':\n",
    "        scoreset_id = entry['target']['scoreset']\n",
    "        scoresets_dict[ scoreset_id ] = {'uniprot': entry['target']['uniprot']['identifier'], \\\n",
    "                                         'offset': entry['target']['uniprot']['offset'], \\\n",
    "                                        'url': 'https://www.mavedb.org/scoreset/' + scoreset_id + '/scores/'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'uniprot': 'P12931',\n",
       "  'offset': 269,\n",
       "  'url': 'https://www.mavedb.org/scoreset/urn:mavedb:00000041-a-1/scores/'},\n",
       " {'uniprot': 'P61073',\n",
       "  'offset': 1,\n",
       "  'url': 'https://www.mavedb.org/scoreset/urn:mavedb:00000048-a-1/scores/'},\n",
       " {'uniprot': 'P37840',\n",
       "  'offset': 0,\n",
       "  'url': 'https://www.mavedb.org/scoreset/urn:mavedb:00000045-c-1/scores/'},\n",
       " {'uniprot': 'P42898',\n",
       "  'offset': 0,\n",
       "  'url': 'https://www.mavedb.org/scoreset/urn:mavedb:00000049-a-2/scores/'},\n",
       " {'uniprot': 'Q9NV35',\n",
       "  'offset': 0,\n",
       "  'url': 'https://www.mavedb.org/scoreset/urn:mavedb:00000056-a-1/scores/'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[val for key, val in scoresets_dict.items() if key in list(scoresets_dict.keys())[:5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download from the URLs the CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, val in scoresets_dict.items():\n",
    "    os.system('wget -O data/MAVEdb/' + key.replace(':', '_') + '.csv ' + val['url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out the mapping betweeen uniprot and MAVE scoreset ID for future use\n",
    "with open('data/MAVEdb/mapping.tsv', 'w') as instream:\n",
    "    wr = csv.writer(instream, delimiter = '\\t')\n",
    "    wr.writerow(['scoreset_id', 'uniprot', 'numAA_offset'])\n",
    "    for key, val in scoresets_dict.items():\n",
    "        wr.writerow([key, val['uniprot'], val['offset']])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process the downloaded scoreset files\n",
    "\n",
    "* Add additional column for uniprot ID of the entry\n",
    "* Parse the AA change text (e.g. 'p.Leu308Pro') separately for WT AA, MUT AA and AA position. Use One-letter Amino Acid notation.\n",
    "* Merge all into the same CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseAAmut(mut_string, offset):\n",
    "    \"\"\"\n",
    "    Given standard HGVS mutation notation (e.g. 'p.Leu308Pro'), give tuple of\n",
    "    (WT_AA, MUT_AA, AA_pos) where WT_AA and MUT_AA are One-letter AA codes and AA_pos \n",
    "    is an integer (amino acid position of the mutation)\n",
    "    \n",
    "    Input:\n",
    "      mut_string: standard HGVS mutation notation\n",
    "      offset: int, number of amino acids to add to the AA pos to adjust it to uniprot numbering\n",
    "    Output:\n",
    "      tuple of (WT_AA, MUT_AA, AA_pos). semicolon-delimited if multiple AA positions are affected.\n",
    "    \"\"\"\n",
    "    d = {'CYS': 'C', 'ASP': 'D', 'SER': 'S', 'GLN': 'Q', 'LYS': 'K',\n",
    "     'ILE': 'I', 'PRO': 'P', 'THR': 'T', 'PHE': 'F', 'ASN': 'N', \n",
    "     'GLY': 'G', 'HIS': 'H', 'LEU': 'L', 'ARG': 'R', 'TRP': 'W', \n",
    "     'ALA': 'A', 'VAL':'V', 'GLU': 'E', 'TYR': 'Y', 'MET': 'M', 'TER': 'X'}\n",
    "    # if contain frameshift or variants that can't be mapped to AA sequence consequence, ignore this\n",
    "    if re.search('fs', mut_string) is not None:\n",
    "        return (None, None, None)\n",
    "    if mut_string.find('?') != -1:\n",
    "        return (None, None, None)\n",
    "    if mut_string.find('*') != -1 and mut_string.find('del') != -1 and mut_string.find('ins') != -1:\n",
    "        return (None, None, None)\n",
    "    cmpd = re.search('(?<=p.)\\[.*\\]', mut_string)\n",
    "    if cmpd is not None: # compound AA change in the form e.g. p.[Tyr19Cys;Asn22Asp;=]\n",
    "        cmpd = str(cmpd.group(0)).strip('[]')\n",
    "        cmpd = cmpd.split(';')\n",
    "    else:\n",
    "        cmpd = [mut_string]\n",
    "    # remove synonymous\n",
    "    cmpd = [i for i in cmpd if i not in ['p.=', '_wt', 'p.?', '_sy', '=']]\n",
    "    cmpd = [i for i in cmpd if i.find('?') == -1 and i.find('*') == -1 and i.find('del') == -1 and i.find('ins') == -1]\n",
    "    if len(cmpd) == 0:\n",
    "        return (None, None, None)\n",
    "    AA_pos = list()\n",
    "    WT_AA = list()\n",
    "    MUT_AA = list()    \n",
    "    for ms in cmpd:\n",
    "        try:\n",
    "            aa_pos = int(re.search('[0-9]+', ms).group(0))\n",
    "        except AttributeError:\n",
    "            print(mut_string)\n",
    "        try:\n",
    "            wt = str(re.search('(?<=p.)[A-Za-z]+', ms).group(0)).upper()\n",
    "        except AttributeError:\n",
    "            wt = str(re.search('^[A-Za-z]+', ms).group(0)).upper()\n",
    "        try:\n",
    "            mut = str(re.search('[A-Za-z\\=]+\\Z', ms).group(0)).upper()\n",
    "        except AttributeError:\n",
    "            print(mut_string)    \n",
    "        if mut not in d.keys() or wt not in d.keys():\n",
    "            if mut == '=':\n",
    "                mut = wt\n",
    "            else:\n",
    "                print(ms)\n",
    "        AA_pos.append( str(aa_pos + offset) )\n",
    "        WT_AA.append( d[wt] )\n",
    "        MUT_AA.append( d[mut] )\n",
    "    return (';'.join(WT_AA), ';'.join(MUT_AA), ';'.join(AA_pos))\n",
    "    \n",
    "# loop through CSV files and read as pd dataframes,\n",
    "# - add additional columns with uniprot ID and scoreset ID\n",
    "# - retain only the relevant columns\n",
    "# - append dataframe to a new file\n",
    "for scoreset_id, val in scoresets_dict.items():\n",
    "    fn = scoreset_id.replace(':', '_')\n",
    "    db = pd.read_csv('data/MAVEdb/' + fn + '.csv', header = 4)\n",
    "    db = db[['hgvs_pro', 'score']]\n",
    "    db['scoreset'] = scoreset_id\n",
    "    db['uniprot'] = val['uniprot']\n",
    "    AAchange = [ parseAAmut(str(mut), int(val['offset'])) for mut in list(db['hgvs_pro']) ] # process `hgvs_pro` column with parseAAmut\n",
    "    db[ ['WT_AA', 'MUT_AA', 'AA_pos'] ] = pd.DataFrame(AAchange, index = db.index)\n",
    "    db = db[ (db['WT_AA'] != db['MUT_AA']) & (db['MUT_AA'] != 'X') ]   # only misense changes, no silent or nonsense mutations\n",
    "    db.to_csv('data/MAVEdb/human_proteins.csv', mode='a', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1139670, 7)\n",
      "(1108702, 7)\n"
     ]
    }
   ],
   "source": [
    "# clean up the written table\n",
    "\n",
    "# remove those extra headers from appending tables into the same CSV file\n",
    "os.system(\"head -1 data/MAVEdb/human_proteins.csv > data/MAVEdb/tmp\")\n",
    "os.system('awk \\'$1 !~ /hgvs/{ print }\\' data/MAVEdb/human_proteins.csv >> data/MAVEdb/tmp')\n",
    "os.system('mv data/MAVEdb/tmp data/MAVEdb/human_proteins.csv')\n",
    "# remove dubious AA changes like 'p.? or p.= or _wt' etc.\n",
    "human_proteins = pd.read_csv('data/MAVEdb/human_proteins.csv')\n",
    "print(human_proteins.shape)\n",
    "bool1 = (human_proteins.hgvs_pro.str.find('?') == -1)         \n",
    "bool2 = (human_proteins.hgvs_pro.str.find('=') == -1)           \n",
    "bool3 = (human_proteins.hgvs_pro.str.find('wt') == -1)          \n",
    "bool4 = (human_proteins.hgvs_pro.str.find('Ter') == -1)\n",
    "human_proteins = human_proteins[bool1 & bool2 & bool3 & bool4]\n",
    "human_proteins = human_proteins[~ human_proteins.WT_AA.isna()]\n",
    "print(human_proteins.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_proteins.to_csv('data/MAVEdb/human_proteins.csv', index=False)\n",
    "\n",
    "# Then replace entries for urn_mavedb_00000049-a-1 with urn_mavedb_00000049-a-1_pub.csv\n",
    "# these are taken from the values from the publication which summarises all experimental conditions in mavedb:00000049."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To determine whether/how to use these values. The trouble is the definition of 'score' varies from one dataset to the other. In some a larger score means higher activity, in some it means more damaging. Some are scaled between 0 and 1, others are centered around 0. Doubtful whether a standard normalization would force them into similar (enough) distributions.\n",
    "\n",
    "`DMSexp_prepare_data` notebook processes the data and turns this into a binary classification (damaging/neutral) problem."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
